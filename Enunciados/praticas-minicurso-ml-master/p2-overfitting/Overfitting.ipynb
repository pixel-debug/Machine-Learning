{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes de come√ßar..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa pr√°tica, iremos entender melhor o conceito de Overfitting e underfitting al√©m de ter o primeiro contato com um m√©todo de aprendizado de m√°quina supervisionado (√Årvore de Decis√£o). Para isso, iremos usar a biblioteca [Scikit Learn](https://scikit-learn.org), al√©m das bibliotecas que usamos na pr√°tica passada: pandas, matplotlib e numpy. Clique no c√≥digo abaixo e pressione ctrl+enter para execut√°-lo.\n",
    "\n",
    "Para isso, se necess√°rio, instale tais bibliotecas usando `pip3 install pandas matplotlib numpy` (em alguns Sistemas Operacionais/configura√ß√µes, voc√™ usar√° `pip` ao inves de `pip3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...um pouquinho mais sobre üêºüêº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\">**M√©todo drop**</a> Remove colunas ou linhas do dataframe. Utilize inplace=True para a modifica√ß√£o ocorrer no dataframe que est√° sendo modificado. Veja exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(5, 4),columns=['ana', 'bruna', 'carol', 'daniel'])\n",
    "print(df)\n",
    "print(\"\\n\\n depois de remover... \\n\\n\")\n",
    "print(df.drop(['carol', 'daniel'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html\">**M√©todo sample**</a> Extrai uma amostra aleat√≥ria do Dataframe. Utilize random_state = \"n√∫mero inteiro\" para que seja embaralhado sempre da mesma forma - importante para [reprodutibilidade dos resultados](https://pt.wikipedia.org/wiki/Reprodutibilidade). Al√©m disso, voc√™ pode remover a amostra selecionada da amostra original por meio dos √≠ndices (precisam ser √∫nicos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(frac=0.6, random_state=1)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remo√ß√£o da amostra selecionada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retirando_sample = df.drop(df_sample.index)\n",
    "df_retirando_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting - Exemplo Ilustrativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A principio, vamos fazer um dataset artificial em que possuimos dois atributos (tamb√©m chamado de caracter√≠scas ou, do ingl√™s, *features*) e duas poss√≠veis sa√≠das (tamb√©m chamado de valor alvo ou classe alvo). Para isso, temos a matriz `x` e o vetor `y` em que, para cada exemplo `i`, cada linha `x[i]` dessa matriz representa esse exemplo (neste caso, representado por dois atributos) e a classe alvo `y[i]`.\n",
    "\n",
    "Veja o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x, y = sklearn.datasets.make_moons(400, noise=0.25)\n",
    "x[:10]#10 primeiras linhas da matriz X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]#lista com 10 primeiros itens do vetor y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa e nas demais pr√°ticas, iremos representar a classe alvo como um vetor `y` e, os atributos, pela matriz `x`.\n",
    "\n",
    "Abaixo, podemos ver a representa√ß√£o gr√°fica deste dataset em que, para cada instancia `i`, o eixo x √© o atributo `x[i][0]` e o eixo y √© o atributo `x[i][1]` a classe alvo `y[i]` √© representada pela cor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1], s=40, c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, no aquivo `arvore_de_decisao.py` implemente a fun√ß√£o `cria_modelo`. Veja a seguir as instru√ß√µes de como implement√°-la.\n",
    "\n",
    "Nessa fun√ß√£o, voc√™ dever√° criar um modelo baseado em arvore de decis√£o, por meio de um treino. Para o treino, use a vari√°vel `x` (que pode ser uma matriz ou DataFrame) em que, cada linha, √© uma inst√¢ncia representada pelos seus atributos, al√©m disso, a `y` √© um vetor ou Series  representando a classe alvo  de cada inst√¢ncia. Coloque como `random_state=1` que √© o seed (semente) da fun√ß√£o aleat√≥ria usada, pois, por padr√£o, a √°rvore de decis√£o do Scikit learn obt√©m os dados de forma ale√°toria. Definindo este parametro, garantimos que o resultado ser√° o mesmo em todas as execu√ß√µes.\n",
    "\n",
    "Al√©m disso, com o objetivo de avaliarmos o overfitting, essa fun√ß√£o possuir√° o parametro `min_samples_split` que \n",
    " que define o m√≠nimo de exemplos necess√°rios para que um nodo da √°rvore efetue a divis√£o. Use esse par√¢metro ao instanciar a √Årvore de Decis√£o. \n",
    "\n",
    "Para implementar essa fun√ß√£o, use a classe `DecisionTreeClassifier`. [Veja a documenta√ß√£o desta classe](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Se necess√°rio, comente a importa√ß√£o abaixo, copie e cole a fun√ß√£o aqui e, logo ap√≥s, volte ela para o arquivo. Para criar/obter o modelo use o [m√©todo fit](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit).  Ap√≥s implementar, execute o teste abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tests TestDecisionTree.test_cria_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo ap√≥s, execute o c√≥digo abaixo para importar a fun√ß√£o criada. Lembre-se de reiniciar o kernel caso fa√ßa alguma modifica√ß√£o na mesma ap√≥s importar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import cria_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, crie um modelo e use a fun√ß√£o `plot_decision_boudary` para gerar o grafico apresentado o dataset ilustrativo com a superf√≠cie de decis√£o do modelo criado. Essa fun√ß√£o est√° no arquivo `util.py`.\n",
    "\n",
    "Na cria√ß√£o do modelo, altere o parametro `min_samples` at√© um valor que voc√™ julgue adequado. Veja o *overfitting* em valores muito baixos (abaixo de 1%, principalmente) e *underfitting* em valores muito altos. Como usualmente implementada, a porcentagem nesta fun√ß√£o √© um valor entre 0 e 1 em que 1 representa 100% 0.5, por exemplo, representa 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from util import plot_decision_boundary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impacto do Overfitting/Underfitting - Estimativa Autom√°tica da Qualidade de Conte√∫do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta pr√°tica, iremos usar dados de 3.294 artigos da Wikip√©dia rotulados manualmente quanto a sua qualidade. \n",
    "\n",
    "Esses artigos passaram por uma avalia√ß√£o pela comunidade de editores da Wikipedia. Tais editores classificaram esses artigos quanto a qualidade da seguinte forma: \n",
    "\n",
    "- **Artigo Destaque (FA)**: Os artigos atribu√≠dos a esta classe s√£o, de acordo com os avaliadores, os melhores artigos da Wikip√©dia.\n",
    "- **Classe A (AC)**: os artigos da Classe A s√£o considerados completos, mas com alguns problemas pendentes que precisam ser resolvidos para serem promovidos a Artigos em destaque.\n",
    "- **Artigo Bons (GA)**: Bons Artigos s√£o aqueles sem problemas de lacunas ou conte√∫do excessivo. Essas s√£o boas fontes de informa√ß√£o, embora outras enciclop√©dias possam fornecer um conte√∫do melhor.\n",
    "- **Classe B (BC)**: os artigos atribu√≠dos a essa classe s√£o considerados √∫teis para a maioria dos usu√°rios, mas carecem de informa√ß√µes mais precisas.\n",
    "- **Classe Inicial (ST)**: os artigos da Classe Inicial ainda est√£o incompletos, embora contenham refer√™ncias e ponteiros para informa√ß√µes mais completas.\n",
    "- **Artigos Rascunhos (SB)**: os artigos de toco s√£o artigos de rascunho, com poucos par√°grafos. Eles tamb√©m t√™m poucas ou nenhumas cita√ß√µes.\n",
    "\n",
    "Assim, [Dalip et. al. (2009)](https://dl.acm.org/citation.cfm?id=1555449) fizeram o preprocessamento desses artigos para serem extra√≠dos indicadores de qualidades tais como: idade do artigo, tamanho, n√∫mero de cita√ß√µes. Com tais indicadores e a classe de qualidade, foi poss√≠vel realizar a predi√ß√£o autom√°tica de qualidade de artigos da Wikip√©dia.\n",
    "\n",
    "Nesta pr√°tica, iremos fazer a previs√£o da qualidade usando os indicadores proposto por [Dalip et. al. (2009)](https://dl.acm.org/citation.cfm?id=1555449) e uma √°rvore de decis√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, uso um DataFrame pandas e [leia o arquivo `wikipedia.csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) e exiba os dados deste dataset. Coloque como o r√≥tulo da linha o id do artigo (ou seja, no dataset, a coluna `id` ser√° a `index_col` do DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de executar a classifica√ß√£o e verificar o acerto no treino e teste, voc√™ dever√° implementar a fun√ß√£o `divide_treino_teste` que est√° no arquivo `arvore_decisao.py`.\n",
    "\n",
    "Essa fun√ß√£o dever√° dividir os dados, de forma aleatoria, em treino e teste.  Para isso, fa√ßa o seguinte: \n",
    "\n",
    "1. Crie o DataFrame `df_treino` por meio do Dataframe `df` e a propor√ß√£o `val_proporcao_treino`, passados como par√¢metro. `val_proporcao_treino` assume um valor de 0 a 1 em que, por exemplo, 0.8 representa que 80% das instancias ser√£o de treino e, o restante, o teste. . O [m√©todo `sample`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) ir√° auxiliar para isso. Us, como par√¢metro `random_state=1`. Esse ser√° o valor da semente (seed) da fun√ß√£o aleat√≥ria para manter sempre os dados embaralhados da mesma forma (o teste unit√°rio s√≥ ir√° funcionar caso tenha colocado a esse valor de semente);\n",
    "\n",
    "2. Conforme dito, o restante das instancias estar√£o em `df_teste`. Uma forma f√°cil de criar o `df_teste` √© obter os elementos que est√£o em `df` e n√£o est√£o em `df_treino`. Para isso, use [o m√©todo `drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) que elimina conlunas ou  linhas de um DataFrame. Para eliminar as linhas, obtenha o id de cada linha do treino usando `df_treino.index`.\n",
    "\n",
    "Em Python uma fun√ß√£o pode retornar mais de um elemento. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xuxu():\n",
    "    a = 2\n",
    "    b = 3\n",
    "    return a,b\n",
    "x,y = xuxu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o seguinte testa para verificar a corretude de seu c√≥digo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tests TestDecisionTree.test_divide_treino_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, execute a fun√ß√£o `divide_treino_teste` com uma divis√£o de 80% de treino e, logo ap√≥s, usando df_treino e df_teste, crie as seguintes vari√°veis:\n",
    "-  `x_treino` : DataFrame que representa, para cada linha do **treino**, todos os atributos de um exemplo do treino. Para isso, elimine a coluna que representa a classe por meio [m√©todo `drop` do DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html), alterando o parametro axis;\n",
    "- `y_treino`: Series que representa, para cada posi√ß√£o `i`, a classe alvo do exemplo `i` representado pelos atributos `x_treino[i]`. A classe alvo est√° na coluna `realClass`;\n",
    "- `x_teste`: Similar ao `x_teste`, por√©m com as instancias do **teste**. \n",
    "- `y_teste`: Similar ao `y_treino`, por√©m, s√£o as classe alvo do teste; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import divide_treino_teste\n",
    "\n",
    "#execute a fun√ß√£o divide_treino_teste corretamente\n",
    "df_treino, df_teste = None\n",
    "\n",
    "#instancias de treino - separe as features x da classe y\n",
    "x_treino = None\n",
    "y_treino = None\n",
    "\n",
    "\n",
    "#instancias de teste - separe as features x da classe y\n",
    "x_teste =  None\n",
    "y_teste = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente agora o m√©todo `faz_classificacao`. Ele passar√° como parametro as vari√°veis `X_treino`, `y_treino`, `X_teste`, `y_teste`, criadas anteriormente al√©m do par√¢metro `min_samples` que define a quantidade m√≠nima de instancias para que se divida um nodo da √°rvore de decis√£o.\n",
    "\n",
    "Assim, esta fun√ß√£o ir√°:\n",
    "\n",
    "1- Criar o modelo a partir dos dados de treino e o parametro `min_samples` (voc√™ pode usar a fun√ß√£o criada anteriormente);\n",
    "\n",
    "2- Realizar a predi√ß√£o usando o [m√©todo predict](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict). Esse m√©todo retorna uma lista de predi√ß√£o em que, para cada posi√ß√£o `i`, retorna o resultado previsto do exemplo representado por `x_teste[i]`;\n",
    "\n",
    "3- A partir da lista obtida pela predi√ß√£o e da vari√°vel `y_teste`, calcule a `acuracia` que √© a propor√ß√£o de acertos, ou seja, $acuracia = acertos/|y_{teste}|$ em que `acertos` √© a quantidade de acertos da predi√ß√£o e $y_{teste}$ √© a lista `y_teste`.\n",
    "\n",
    "Dicas:\n",
    "- caso tenhamos duas listas `a` e `b`, ao fazer a opera√ß√£o `a==b`, ele retornar√° uma lista em que o valor  de cada posi√ß√£o ser√° igual a verdadeiro caso `a==b`.\n",
    "- np.sum soma os valores de um vetor, caso os valores sejam booleanos, ser√° considerado True=1 e False=0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo ap√≥s, execute o teste abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tests TestDecisionTree.test_faz_classificacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import faz_classificacao\n",
    "y_predicted,acuracia =  None\n",
    "\n",
    "print(\"Acur√°cia: {0}\".format(acuracia)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por meio da fun√ß√£o `plot_performance_min_samples` crie um gr√°fico em que o eixo `x` √© a varia√ß√£o do par√¢metro `min_samples` e, o eixo `y`, representar√° a acur√°cia. Voc√™ dever√° veriar o `min_samples` de 0.001 at√© 0.7 de 0.01 em 0.01 passos. Esse gr√°fico possuir√° duas linhas: representando a **acur√°cia no treino** durante a varia√ß√£o do `min_samples` e, a outra, a **acur√°cia do teste** com os diversos valores de `min_sample`.\n",
    "\n",
    "- foi usada a fun√ß√£o arange do numpy para o for (ao inv√©s de range). Pois o range permite apenas passos com valores inteiros;\n",
    "- para obter a acur√°cia no treino, o teste dever√° possuir as mesmas instancias do treino;\n",
    "- Para plotar foi usado o matplotlib veja: [https://matplotlib.org/users/pyplot_tutorial.html](https://matplotlib.org/users/pyplot_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute abaixo a fun√ß√£o plot_performance_min_samples usando as veri√°veis X_treino,y_treino,X_teste,y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import plot_performance_min_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva abaixo **um paragrafo** descrevendo o que pode ser visto no gr√°fico e quando h√° overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o! Nesta nossa pr√°tica, variamos o parametro no teste para ver o impacto da vari√°vel `min_samples_split` no mesmo. Por√©m,  caso quisessems comparar este classificador com outro, **n√£o devemos usar informa√ß√£o do teste para construir o classificador** pois o teste deve reproduzir \"o mundo real\" e n√£o saberiamos os valores do teste a priori.  \n",
    "\n",
    "Assim, n√£o √© metodologicamente correto escolher um par√¢metro utilizando do teste. Para resolver esse problema, poderemos ter uma parti√ß√£o de valida√ß√£o. \n",
    "\n",
    "\n",
    "**Opcional**: Divida os dados em 60% de treino, 20% de valida√ß√£o e 20% de teste. Use a parti√ß√£o de valida√ß√£o para descobrir o melhor parametro `min_samples` (melhor=maior acur√°cia). Por meio dele, treine o modelo e calcule o resultado no teste. Al√©m da acur√°cia, use a fun√ß√£o [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) para exibir outras m√©tricas de avalia√ß√£o dispon√≠veis no Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opcional¬≤** Como a qualidade pode ser encarada como uma nota em uma escala, modelar este problema como regress√£o pode ser melhor. Por isso, use [regress√£o e RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) e apresente o [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error) obtido. Usando o treino e **valida√ß√£o** descubra o melhor valor para `min_samples_split`, apresente o grafico, e use o melhor parametro obtido na valida√ß√£o para o teste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
