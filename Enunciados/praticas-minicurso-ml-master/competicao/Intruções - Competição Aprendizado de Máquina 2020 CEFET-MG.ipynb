{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificação Automática do Gênero do Filme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você recebeu este dataset e seu objetivo é estimar o genero dele (comédia ou ação) de acordo com seus atributos - contidos neste dataset.\n",
    "\n",
    "**O que você deverá fazer?**\n",
    "\n",
    "- Explorar e entender os dados\n",
    "- Criar os atributos de treino para isso, voce deverá:\n",
    "    - Verificar a existencia de valores ausentes e verificar estratégias para lidar com eles\n",
    "    - Descobrir a melhor forma de representar valores categóricos e textual (veja explicação abaixo) \n",
    "- Avaliar e descobrir o melhor método podendo considerar:\n",
    "     - Qual são os melhores parametros?\n",
    "     - Quais são os melhores métodos?\n",
    "     - A combinação de mais de um método é útil?\n",
    "     - Qual é a melhor representação de uma instancia? Ou seja, qual é a melhor forma de preprocessar meus atributos? Fazer normalização dos atributos auxiliará? Como lidar com dados inexistentes? \n",
    "     - Pode-se criar modelos de representações diferentes e combiná-los (Multiview)\n",
    "     - Como lidar com um dataset que possui muito mais instancias de uma classe que outra? Isso pode fazer com que alguns métodos ficam tendenciosos para a classe que possui mais elementos.  Uma estratégia é usar undersampling: caso tenhamos uma classe com 10.000 e outra com 5.000, utilize uma amostra de 5.000 instancias da primeira classe para o treinamento.\n",
    "     \n",
    "Lembrem-se: temos pouco tempo, então, faça de um jeito simples, veja e investigue os erros e, logo após, vá incrementando..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O que será entregue**\n",
    "\n",
    "Após descoberto o melhor modelo, você receberá [um dataset como esse](datasets/movies_amostra_teste_ex.csv) - sem a informação sobre genero - e você deverá prever qual será o genero do film. Após avaliar vários modelos e descobrir o melhor, você entregará seu código zipado junto com a predição por instancia em um arquivo de nome `predict.txt` no seguinte formato: Para cada linha o exemplo de teste, o valor `comedy` ou `action` definindo seu genero. Por exemplo, caso tenhamos um dataset de teste de 10 instancias, uma possível saída seria: \n",
    "\n",
    "```\n",
    "comedy\n",
    "comedy\n",
    "action\n",
    "action\n",
    "action\n",
    "comedy\n",
    "comedy\n",
    "action\n",
    "comedy\n",
    "action\n",
    "```\n",
    "\n",
    "O professor terá as saídas esperadas do teste e irá compará-lo a partir da saída gerada. Caso o arquivo não tenha esse nome ou esteja fora do padrão, o resultado da equipe será desconsiderado. **Haverá duas rodadas e, cada rodada, um dataset de teste diferente**.\n",
    "\n",
    "\n",
    "Para facilitar a reprodutibilidade, a implementação do modelo deverá estar bem organizada seguindo as seguintes especificações: \n",
    "\n",
    "- O modelo a ser gerado deverá ser subclasse de `MetodoAprendizado`. Nessa subclasse, você poderá facilmente criar um metodo com multiplos métodos de aprendizado de máquina e/ou também, para diferentes representações você pode passar como parametro no construtor as colunas do dataframe de cada visão. Por exemplo, caso tenhamos em uma visão os atributos `a'`, `b`, `c` e, em outro os atributos `x`, `y` e `z`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visao_1 = ['a','b','c']\n",
    "visao_2 = ['x','y','z']\n",
    "# o código não irá executar pois não implementamos essa classe ainda\n",
    "metodo = MetodoCompeticao([ visao_1, visao_2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, no método `eval` você deverá apenas filtrar o dataframe por visão e gerar um vetor de predição por visão para, logo após, combiná-lo por maioria de votos, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regras** \n",
    "\n",
    "- O conhecimento e geração dos atributos/preprocessamente e método deve vir apenas no dataset `movies_amostra.csv`. Por exemplo, não é permitido adicionar um valor faltante a um filme baseado no seu conhecimento sobre o mesmo - ou de outros dados da Internet. A unica exceção a essa regra é o uso de palavras-chaves (que podem ser criadas por vocẽ) para geração de atributos (detalhado nas seções a seguir).\n",
    "\n",
    "- Da mesma forma, o treino deve ser criado usando **apenas** as instancias do arquivo `movies_amostra.csv`. Por exemplo, o teste `movies_amostra_teste_ex.csv` não pode ser usado para criar dados de treino e nem outros dados fornecidos pelo professor ou externo. \n",
    "\n",
    "- Não é permitido salvar o objeto em arquivo (usando pickle, por exemplo) para ser lido na função `gerar_saidas_teste`\n",
    "\n",
    "- O teste deve ser reprodutível, ou seja, resultado dos experimentos do código executado no computador do professor deve ter o mesmo resultado daquele obtido pelos alunos. \n",
    "\n",
    "- A organização dos arquivos deve ser respeitada, além do formato do `predict_grupoXX.txt`.\n",
    "\n",
    "- O arquivo de saída deve ser exatamente o nome `predict_grupoXX.txt` sendo que XX é substituido pelo número do grupo e o formato conforme especificado. \n",
    "\n",
    "Caso a equipe não siga essas regras, ela será desclassificada. Caso haja algum problema, a equipe deve comunicar ao professor no chat do Discord.\n",
    "\n",
    "**Duvidas: ** Todas as dúvidas devem ser postadas no canal `#competicao`. Para não beneficiar uma equipe ou outra, as dúvidas não serão esclarecidas no privado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organização dos arquivos: **\n",
    "\n",
    "- Os arquivos `metodo.py`, `resultado.py` e `avaliacao.py` na pasta `base_am` devem permanecer sem modificações\n",
    "\n",
    "- Qualquer método de aprendizado de maquina usado deverá estar no arquivo `metodo_competicao.py` na pasta `competicao_am` e ser subclasse de `MetodoAprendizadoMaquina` - já existe um exemplo pronto.\n",
    "    \n",
    "- Qualquer modificação da  avaliação experimental deve estar em `avaliacao_competicao.py` na pasta `competicao_am`. Alteração do experimento deve ser subclasse de `Experimento` e a as classes para variação dos parametros devem ser subclasses de `OtimizacaoObjetivo` e estar nesse mesmo arquivo. Há um exemplo de implementação da classe `OtimizacaoObjetivo` nesse arquivo.\n",
    "\n",
    "- Caso seja necessária alguma modificação em classes do `resultado.py`, você deve fazer um arquivo `resultado_competicao.py` fazendo subclasses/associações das classes especificadas em `resultado.py`\n",
    "    \n",
    "- `preprocessamento_atributos_competicao.py`: Usará o arquivo `preprocessamento_atributos`  (se necessário) e criará os atributos do modelo. Você pode também criar as classes que desejar para criação dos atributos nesse arquivo. \n",
    "- Arquivo `gerar_resultado_teste.py` na pasta `competicao_am` que você deverá apresentar o código para gerar a saída para o dataset fornecido pelo professor. Esse código deverá usar o arquivo `datasets/movies_amostra.csv` para treino - nenhum outro arquivo a mais, fazer todo o processamento necessario, criação do modelo e gerar a saída. A função principal que gera a saída deve ser obrigatoriamente `gerar_saida_teste` - já com um exemplo implementado. Esse código deve estar claro e que seja possível o professor reproduzir o mesmo resultado. Há um exemplo pronto também. \n",
    "\n",
    "- Haverá `competicao.ipynb` explicando qual foi a solução adotada passo a passo: (a) como se escolheu o conjuntos de parametros? (c) qual foi a representação adotada?  (d) Como vocẽs chegaram nesta representação? ;(d) quais métodos foram adotados? (e) deixar claro passo a passo a implementação da função `gerar_saida_teste`do arquivo `gerar_resultado_teste.py`. Nesse arquivo Jupyter não haverá muito código apenas, se necessário, chamada as funções/métodos dos arquivos `.py` acima. Durante a competição, vocês testarão diversas representações e modelos. Porém, neste arquivo, você deverá usar apenas a representação e modelo que você considerou mais efetivo. Coloque também um paragrafo explicando o caminho e tentativas que não deram tanto certo. Além disso, nesse arquivo você deverá   Caso tenha sido feito uso de palavras chaves, lista-las e explicar como chegou nas mesmas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dinamica da competição**\n",
    "\n",
    "Haverá 2 rodadas, cada rodada terá 3 fases: \n",
    "\n",
    "1. **Elaboração da solução e descoberta do melhor modelo**: nesta fase, você criará a solução que você julgar a melhor. Logo após, você enviará essa solução pronta no Moodle.\n",
    "2. **Geração do resultado no dataset fornecido pelo professor**: logo após a entrega, estará disponível um dataset de teste para você gerar a predição. Nessa fase, você deverá usar seu código (submetido na fase anterior) para prever o resultado desse dataset. Porém, você não poderá alterar nenhuma parte de seu código, pois ele já foi submetido. Por isso, não esqueça de [testar seu código com este dataset](teste_ex.csv). Logo após, você deverá enviar o seu resultado via Moodle - o prazo para envio será de apenas 1 dia após da entrega de sua solução. \n",
    "3. **Apresentação do resultado**: com os resultados de cada equipe, o professor irá apresentar o ranking de cada solução por equipe\n",
    "\n",
    "Os prazos não serão alterados devido ao atraso de alguma equipe. Instruções para implementação das fases 1 e 2 serão dadas a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critérios de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os códigos serão classificados de acordo com a macro F1. Caso ocorra empate, será feito desempate na seguinte ordem: \n",
    "\n",
    "1. F1 Score da classe `Action`\n",
    "2. Tempo de execução da função `gerar_saida_teste`\n",
    "3. Caso seja a segunda rodada, os critérios acima, nesta ordem, da primeira rodada\n",
    "4. Clareza do código e elegancia da solução\n",
    "\n",
    "O resultado final será o resultado da segunda rodada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Dataset de treino e avaliação](datasets/movies_amostra.csv)\n",
    "- [Dataset de teste - exemplo](datasets/movies_amostra_teste_ex.csv)\n",
    "- [Dataset de teste - primeira rodada](datasets/movies_amostra_teste_1.csv): a ser disponibilizado pelo professor na 2ª fase da primeira rodada\n",
    "- [Dataset de teste - segunda rodada](datasets/movies_amostra_teste_2.csv): a ser disponibilizado pelo professor na 2ª fase da segunda rodada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de representações de dados categóricos e textual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria dos métodos de aprendizado de máquina esperam como entrada valores numéricos. Por isso, temos que fazer tratamento quando o dado é categorico. Além disso, outro tipo de dado que precisamos de tratamento especial é o texto corrido que pode trazer muita informação relevante para tarefas de aprendizado de máquin. Nesta seção, será explicado um pouco sobre algumas abordagens da mais simples até a mais usada\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação para um número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A forma mais simples de se fazer a transformação é simplesmente mapear esse atributo para um valor numérico. Veja o exemplo abaixo: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_jogos = pd.DataFrame([   [\"boa\",\"nublado\",\"não\"],\n",
    "                            [\"boa\",\"chuvoso\",\"não\"],\n",
    "                           [\"média\",\"nublado\",\"sim\"],\n",
    "                         [\"fraca\",\"chuvoso\",\"não\"]],\n",
    "                        columns=[\"disposição\",\"tempo\",\"jogar volei?\"])\n",
    "df_jogos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, temos dois atributos disposição do jogador e tempo e queremos prever se o jogar irá jogar volei ou não. Tanto os atributos quanto a classe podem ser mapeados como número. Além disso, o atributo `disposicao` é um atributo que representa uma escala - o que deixa essa forma de tranformação bem adequada para esse atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def mapeia_atributo_para_int(df_data:pd.DataFrame, coluna:str, dic_nom_to_int: Dict[int,str]):\n",
    "    for i,valor in enumerate(df_data[coluna]):\n",
    "        valor_int = dic_nom_to_int[valor]\n",
    "        df_data[coluna].iat[i] = valor_int\n",
    "\n",
    "        \n",
    "df_jogos = pd.DataFrame([   [\"boa\",\"nublado\",\"sim\"],\n",
    "                            [\"boa\",\"chuvoso\",\"não\"],\n",
    "                           [\"média\",\"ensolarado\",\"sim\"],\n",
    "                         [\"fraca\",\"chuvoso\",\"não\"]],\n",
    "                        columns=[\"disposição\",\"tempo\",\"jogar volei?\"])\n",
    "dic_disposicao = {\"boa\":3,\"média\":2,\"fraca\":1}\n",
    "mapeia_atributo_para_int(df_jogos, \"disposição\", dic_disposicao)\n",
    "\n",
    "dic_tempo = {\"ensolarado\":3,\"nublado\":2,\"chuvoso\":1}\n",
    "mapeia_atributo_para_int(df_jogos, \"tempo\", dic_tempo)\n",
    "\n",
    "dic_volei = {\"sim\":1, \"não\":0}\n",
    "mapeia_atributo_para_int(df_jogos, \"jogar volei?\", dic_volei)\n",
    "df_jogos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarização dos atributos categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Podemos fazer a binarização dos atributos categóricos em que, cada valor de atributo transforma-se em uma coluna que recebe `0` caso esse atributo não exista e `1`, caso contrário. Em nosso exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessamento_atributos import BagOfItems\n",
    "df_jogos = pd.DataFrame([   [4, \"boa\",\"nublado\",\"sim\"],\n",
    "                            [3,\"boa\",\"chuvoso\",\"não\"],\n",
    "                           [2,\"média\",\"ensolarado\",\"sim\"],\n",
    "                         [1,\"fraca\",\"chuvoso\",\"não\"]],\n",
    "                        columns=[\"id\",\"disposição\",\"tempo\",\"jogar volei?\"])\n",
    "dic_disposicao = {\"boa\":3,\"média\":2,\"fraca\":1}\n",
    "\n",
    "\n",
    "bag_of_tempo = BagOfItems(0)\n",
    "#veja a implementação do método em preprocesamento_atributos.py\n",
    "df_jogos_bot = bag_of_tempo.cria_bag_of_items(df_jogos,[\"tempo\"])\n",
    "df_jogos_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como existem vários valores no teste que você desconhece, se fizermos dessa forma, atributos que estão no teste poderiam estar completamente zerados no treino, sendo desnecessário, por exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_treino = df_jogos[:2]\n",
    "df_jogos_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_teste = df_jogos[2:]\n",
    "df_jogos_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, o tempo ensolarado não está no treino e, assim, não haveria esse atributo no treinamento. Assim, a forma mais correta de fazermos é (a) descobrirmos a lista de valores no treino e, logo após, aplicamos ela no teste. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_tempo = BagOfItems(0)\n",
    "df_jogos_bot_treino = bag_of_tempo.cria_bag_of_items(df_jogos_treino,[\"tempo\"])\n",
    "df_jogos_bot_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_bot_teste = bag_of_tempo.aplica_bag_of_items(df_jogos_teste,[\"tempo\"])\n",
    "df_jogos_bot_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o impacto no resultado não é tão grande, muitas vezes optamos por fazer binarização no dataset completo, por simplicidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como veremos no próximo exemplo, a binarização pode gerar milhares de atributos pois, em um exemplo completo, uma coluna pode assumir muitos valores. Por isso, colocamos um dataframe separado com tais colunas - neste caso, o `df_jogos_bot`. Se desejar, você pode juntar dois DataFrames pelo `id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_full = pd.merge(df_jogos, df_jogos_bot, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso exemplo, as colunas que representam os atores principais podem ser binarizadas. Abaixo, veja um sugestão de como fazer em dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso caso, podemos colocar os atores todos em um \"Bag of Items\". Os atores são representados por as colunas `ator_1`, `ator_2`,..., `ator_5`. Podemos fazer da forma mais simples, que é usando o dataset todo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessamento_atributos import BagOfItems\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/movies_amostra.csv\")\n",
    "\n",
    "\n",
    "obj_bag_of_actors = BagOfItems(min_occur=3)\n",
    "\n",
    "#boa=bag of actors ;)\n",
    "df_amostra_boa = obj_bag_of_actors.cria_bag_of_items(df_amostra,[\"ator_1\",\"ator_2\",\"ator_3\",\"ator_4\",\"ator_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amostra_boa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que temos bastante atributos um para cada ator. Mesmo sendo melhor possuirmos poucos atributos e mais informativos, um método de aprendizado de máquina pode ser capaz de usar essa quantidade de forma eficaz. Particularmente, o [SVM linear](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) e o [RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) são métodos que conseguem ir bem nesse tipo de dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo após, pode-se juntar os dados dos atores com os demais: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_final = pd.merge(df_amostra, df_amostra_boa, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é a forma mais prática de fazer, porém, conforme já mencionado, alguns atributos seriam inúteis para o teste. Isso pode fazer com que o resultado reproduza menos o mundo real - neste caso, é muito possível que a diferença seja quase insignificante. Mas, caso queiramos fazer da forma \"mais correta\", temos que considerar apenas o treino para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supondo que 80% da amostra é treino\n",
    "df_treino_amostra = df_amostra.sample(frac=0.8, random_state = 2)\n",
    "df_teste_amostra = df_amostra.drop(df_teste_amostra.index)\n",
    "#min_occur=3 definie o minimo de ocorrencias desse ator para ser considerado\n",
    "#pois, um ator que apareceu em poucos filmes, pode ser menos relevante para a predição do genero\n",
    "obj_bag_of_actors = BagOfItems(min_occur=3)\n",
    "df_treino_amostra_boa = obj_bag_of_actors.cria_bag_of_items(df_treino_amostra,[\"ator_1\",\"ator_2\",\"ator_3\",\"ator_4\",\"ator_5\"])\n",
    "df_teste_amostra_boa = obj_bag_of_actors.aplica_bag_of_items(df_teste_amostra,[\"ator_1\",\"ator_2\",\"ator_3\",\"ator_4\",\"ator_5\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas vezes, temos textos que podem ser relevantes para uma determinada tarefa de aprendizado d máquina. Por isso, temos que representar tais elementos para nosso método de aprendizado de máquina. \n",
    "\n",
    "A forma mais usual para isso, é a `Bag of Words` em que cada palavra é um atributo e, o valor dela, é a frequencia dele no texto (ou algum outro valor que indique a importancia dessa palavra no texto).\n",
    "\n",
    "Por exemplo, caso temos as frases `A casa é grande`, `A casa é verde verde` em que cada frase é uma instancia diferente. A representação seria da seguinte forma: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bow = {\"a\":[1,1],\n",
    "         \"casa\":[1,1],\n",
    "         \"é\":[1,1],\n",
    "         \"verde\":[0,2]\n",
    "        }\n",
    "df_bow = pd.DataFrame.from_dict(dic_bow)\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da forma que fizemos acima, usamos a frequencia de um termo para definir sua importancia no texto, porém, existem termos que possuem uma frequencia muito alta e importancia baixa: são os casos dos artigos e preposições por exemplo, pois, eles não discriminam o texto. \n",
    "\n",
    "Uma forma de mensurar o porder discriminativo das palavras é usando a métrica `TF-IDF`. Para calcularmos essa métrica, primeiramente calculamos a frequencia de um termo no documento (TF) e, logo após multiplamos pelo IDF. \n",
    "A fórmula para calcular o TF-IDF do termo $i$ no documento (ou instancia) $j$ é a seguinte:\n",
    "\n",
    "\\begin{equation}\n",
    "    TFIDF_{ij} = TF_{ij} \\times IDF_i\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    TF_{ij} = log(f_{ij})\n",
    "\\end{equation}\n",
    "\n",
    "em que $f_{ij}$ é a frequencia de um termo $i$ no documento $j$. Usa-se o `log` para suavizar valores muito altos e o $IDF$ (do inglês, _Inverse Document Frequency_) do termo $i$ é calculado da seguinte forma:\n",
    "\n",
    "\\begin{equation}\n",
    "    IDF_i = log(\\frac{N}{n_i})\n",
    "\\end{equation}\n",
    "\n",
    "em que $N$ é o número de documentos da coleção e $n_i$ é o número de documentos em que esse termo $i$ ocorre. Espera-se que, quanto mais discriminativo o termo, em menos documentos esse termo irá ocorrer e, consequentemente, o $IDF$ deste termo será mais alto. \n",
    "\n",
    "Por exemplo, considere as palavras `de`, `bebida` e `cerveja`. `cerveja` é uma palavra mais discriminativa do que `bebida`; e `bebibda` é mais discriminativo do que a preposição `de`. Muito provavelmente teremos mais frequentemente termos menos discriminativos. Por exemplo, se tivermos uma coleção de 1000 documentos,   `de` poderia ocorrer em 900 documentos,  `bebida` em 500 e `cerveja` em 100 documentos. Se fizermos o calculo, veremos que quanto mais discriminativo um termo, mais alto é seu IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "N = 1000\n",
    "n_de = 900\n",
    "n_bebida = 500\n",
    "n_cerveja = 100\n",
    "\n",
    "IDF_de = math.log(N/n_de)\n",
    "IDF_bebida = math.log(N/n_bebida)\n",
    "IDF_cerveja = math.log(N/n_cerveja)\n",
    "\n",
    "print(f\"IDF_de: {IDF_de}\\tIDF_bebida:{IDF_bebida}\\tIDF_cerveja:{IDF_cerveja}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca `scikitlearn`também já possui uma classe [TFIDFVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) que transforma um texto em um vetor de atributos usando o TF-IDF para o valor referente a relevancia deste termo. Veja um exemplo na coluna `resumo` do nosso dataset de filme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessamento_atributos import BagOfWords\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/movies_amostra.csv\")\n",
    "bow_amostra = BagOfWords()\n",
    "df_bow_amostra = bow_amostra.cria_bow(df_amostra,\"resumo\")\n",
    "df_bow_amostra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como são muitos atributos, pode parecer que não ficou corretamente gerado. Mas, filtrando as palavras de um determinado resumo você verificará que está ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow_amostra[[\"in\",\"lake\", \"high\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que também é uma representação muito extensa, com dezenas de milhares de atributos. Como a representação dos autores e dos resumos, dessa forma, ficou com muitos atributos uma sugestão é fazer modelos separados e combinar as suas predições. Você pode pensar em várias formas de combinação:\n",
    " \n",
    "- Usar três representações: dos atores, do resumo e dos demais dados, combiná-las usando votação por maioria\n",
    "\n",
    "- Verificar a  predição com maior probabilidade - usando o método [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não fique preso apenas nessas representações. Vocês podem tentar fazer representações mais sucintas, como, por exemplo: para preprocessar os dados da equipe do filme (atores, diretor e escritor), calcule o número de filmes de comédia que membros da equipe  participaram e, logo após, o número de filme de ação. Neste caso, como você usará a classe, você deverá usar **apenas** os dados de treino. No caso do resumo, você pode utilizar palavras chaves. Por exemplo, faça uma lista de palavras chaves que remetem \"ação\" e contabilize o quantidade dessas palavras chaves no resumo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como avaliar modelos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visando uma melhor organização do código e para que vocês possam ter a experiencia de adaptar códigos dos outros - com restrições - vocês deverão fazer as implementações apenas nos arquivos de final \"competição\" fazendo subclasses/associações com as classes presentes nos arquivos `avaliacao.py`, `resultado.py` e `metodo.py`. \n",
    "\n",
    "Em `metodo_competicao.py` e `avaliacao_competicao` fizemos um exemplo simples usando nosso BOW para vocês entenderem o que deve ser feito nessa tarefa. Em `metodo_competicao.py` fizemos um método exemplo nele, temos que preprocessar e gerar alguns atributos. Para isso, fizemos a chamada do método de preprocessamento dentro dele com funções implementadas em `preprocessamento_atributos_competicao.py`. Não houv necessidade, porém, você poderia criar novas classes de tipos diferentes de preprocessamento e geração de atributos além de poder criar subclasses de BagOfWords para fazer algum preprocessamento diferente dessas classes.\n",
    "\n",
    "De forma similar a prática de avaliação, você deve gerar experimentos, analisar e entende-los. Investigue quando su método é bom o ruim e, com isso, tente melhorá-lo. Para isso, analise vários tipos de representações, métodos e suas combinações além de parametros para descobrir qual é o melhor. Dentre analises interessantes, tente refletir qual a classe que o método erra mais, se em algum grupo de instancia que ocorreu erro há alguma particularidade - analisando, principalmente, seus atributos. Verifique também se está ocorrendo overfitting/underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from base_am.resultado import Fold\n",
    "from base_am.avaliacao import Experimento\n",
    "from competicao_am.metodo_competicao import MetodoCompeticao\n",
    "from competicao_am.avaliacao_competicao import OtimizacaoObjetivoSVMCompeticao, OtimizacaoObjetivoRandomForest\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/movies_amostra.csv\")\n",
    "\n",
    "arr_folds = Fold.gerar_k_folds(df_amostra, val_k=5, col_classe=\"genero\",\n",
    "                            num_repeticoes=1, num_folds_validacao=4,num_repeticoes_validacao=1)\n",
    "scikit_method = LinearSVC(random_state=2)\n",
    "\n",
    "\n",
    "ml_method = MetodoCompeticao(scikit_method)\n",
    "\n",
    "ClasseObjetivo = OtimizacaoObjetivoSVMCompeticao\n",
    "#colocamos apenas 5 trials para ir mais rápido. Porém, algumas vezes precisamos de dezenas, centenas - ou milhares - de trials para conseguir uma boa configuração\n",
    "#Isso depende muito da caracteristica do problema, da quantidade de parametros e do impacto desses parametros no resultado\n",
    "experimento = Experimento(arr_folds, ml_method=ml_method,\n",
    "                    ClasseObjetivoOtimizacao=ClasseObjetivo,\n",
    "                    num_trials=2)\n",
    "print(f\"MACRO F1: {experimento.macro_f1_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ConvergenceWarning que você está vendo é por que o SVM, assim como vários métodos de aprendizado de máquina, tentam convergir para um determinado resultado e, por algum motivo, para uma das representações o SVM não está convergindo. Você pode aumentar o valor do parametro que regula isso ou até alterar a representação para deixá-la mais informativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que recomendo fazer: para descobrir a melhor representação e método, use diretamente a classe `MetodoCompeticao`  para ir brincando e descartando representações que aparentemente, não foram tão boas com os parametros padrão. Logo após, utilize as mais promissoras e analise o resultado. Sempre considere, além da macro-f1, a precisão e revocação por classe além da matriz de confusão. Use a classe `Experimento` para analisar o impacto dessas representações também considerando a melhor configuração de parametros. Se desejar, crie uma subclasse de `Experimento` em \"avaliacao_competicao.py\" para gerar algumas análises, por exemplo, gerar a matriz de confusão que agrupa o resultado dos folds. Para agregar as matrizes de confusão, você pode gerar tanto a média da quantidade por fold ou fazer o somatório de todas elas. \n",
    "\n",
    "Este foi um exemplo com apenas um modelo para as duas representações. Você poderia, para cada representação, criar modelos distintos e com parametros distintos. Para isso, você pode mudar o constutor da classe `MetodoCompeticao`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma boa prática é salvar seus experimentos em arquivos, com algum nome sugestivo. Assim, você não precisará rodar ele novamente para analisá-lo. Uma excelente e bem organizada forma é usar um banco de dados. Porém, você pode simplesmente salvar o objeto em um arquivo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump( experimento, open( \"resultados/exp_bow_e_bag_of_actors.p\", \"wb\" ) )\n",
    "\n",
    "experimento = pickle.load( open( \"resultados/exp_bow_e_bag_of_actors.p\", \"rb\" ) )\n",
    "print(f\"MACRO F1: {experimento.macro_f1_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração do resultado no dataset fornecido pelo professor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de definido a melhor solução, você deverá aplicá-la no teste fornecido pelo professor. Para esse teste você deverá usar a função `gerar_saida_teste` do arquivo `gerar_resultado_teste.py` criada por você na fase de elaboração da solução. Nele, você deverá usar o dataset completo `movies_amostra.csv` **nenhum dado a mais e sem nenhum preprocessamento**. O preprocessamento e geração dos atributos deverá ser feito na própria função (como no exemplo já implementado). Você poderá alterar essa função - até a data de entrega **de seu código**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from competicao_am.gerar_resultado_teste import gerar_saida_teste\n",
    "\n",
    "#altere aqui para o número correspondente ao seu grupo\n",
    "num_grupo = 0 \n",
    "\n",
    "#leia o dataset fornecido pelo professor (coloquei apenas um exemplo, na entrega, será outro)\n",
    "df_amostra_teste = pd.read_csv(\"datasets/movies_amostra_teste_ex.csv\")\n",
    "\n",
    "gerar_saida_teste(df_amostra_teste,\"genero\", num_grupo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprime a saida gerada\n",
    "with open(f\"predict_grupo_{num_grupo}.txt\", \"r\") as file_predict:\n",
    "    for line in file_predict:\n",
    "        print(line,end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
